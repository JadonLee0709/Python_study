# server_stock_api.py
# Stock analysis API for iOS (Route A): Python server + iOS app(SwiftUI)

import re
import time
from typing import Optional, List, Dict, Any
from urllib.parse import quote

import numpy as np
import pandas as pd
import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed

from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware

# =============================
# Config
# =============================
BASE_URL = "https://finance.naver.com/item/sise_day.naver?code={code}&page={page}"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://finance.naver.com/",
}
SEARCH_HEADERS = {**HEADERS, "Referer": "https://search.naver.com/"}

FIXED_WINDOWS = (5, 20, 60, 120)

CODE_RE = re.compile(r"\b(\d{6})\b")

FALLBACK_MAP = {
    "ì‚¼ì„±ì „ì": "005930",
    "ì‚¼ì„±ì „ììš°": "005935",
    "ë„¤ì´ë²„": "035420",
    "NAVER": "035420",
    "ì¹´ì¹´ì˜¤": "035720",
    "SKí•˜ì´ë‹‰ìŠ¤": "000660",
    "í˜„ëŒ€ì°¨": "005380",
    "ê¸°ì•„": "000270",
}

# ê°„ë‹¨ ìºì‹œ (ì„œë²„ ë¶€í•˜/ë„¤ì´ë²„ ì°¨ë‹¨ ë°©ì§€ìš©)
_CACHE: Dict[str, Dict[str, Any]] = {}
CACHE_TTL_SEC = 60  # ê°™ì€ code/payload ìš”ì²­ì´ 60ì´ˆ ë‚´ë©´ ìºì‹œ ë°˜í™˜


# =============================
# Utils: code resolving
# =============================
def pick_code_from_text(text: Optional[str]) -> Optional[str]:
    if not text:
        return None
    m = CODE_RE.search(text)
    return m.group(1) if m else None


def get_code_from_naver_search(query: str) -> Optional[str]:
    url = f"https://search.naver.com/search.naver?query={quote(query)}"
    try:
        r = requests.get(url, headers=SEARCH_HEADERS, timeout=12)
        r.raise_for_status()
    except Exception:
        return None

    html = r.text

    m = re.findall(r"/item/(?:main|coinfo|sise_day)\.naver\?[^\"'>]*\bcode=(\d{6})", html)
    if m:
        return m[0]

    m = re.findall(r'"(?:code|stockCd)"\s*:\s*"(\d{6})"', html)
    if m:
        return m[0]

    soup = BeautifulSoup(html, "html.parser")
    text = soup.get_text(" ")

    m = re.search(r"\b(\d{6})\b(?=[^\n]{0,40}\b(?:KOSPI|KOSDAQ|KRX)\b)", text, re.I)
    if m:
        return m.group(1)

    m = CODE_RE.findall(text)
    if m:
        # ì¤‘ë³µ ì œê±° í›„ ì²« ë²ˆì§¸
        seen = []
        for c in m:
            if c not in seen:
                seen.append(c)
        return seen[0] if seen else None

    return None


def resolve_to_code(user_input: str) -> Optional[str]:
    s = (user_input or "").strip()
    c = pick_code_from_text(s)
    if c:
        return c
    if s in FALLBACK_MAP:
        return FALLBACK_MAP[s]
    return get_code_from_naver_search(s)


# =============================
# Crawling (Thread-based)
# =============================
def _fetch_page(code: str, page: int) -> pd.DataFrame:
    url = BASE_URL.format(code=code, page=page)
    try:
        res = requests.get(url, headers=HEADERS, timeout=15)
        res.raise_for_status()
        tables = pd.read_html(res.text, match="ë‚ ì§œ")
        if not tables:
            return pd.DataFrame()
        df = tables[0]
    except Exception:
        return pd.DataFrame()

    df = df.dropna(how="any")
    if "ë‚ ì§œ" not in df.columns or df.empty:
        return pd.DataFrame()

    df = df[df["ë‚ ì§œ"].astype(str).str.contains(r"\d{4}\.\d{2}\.\d{2}", na=False)]
    if df.empty:
        return pd.DataFrame()

    df = df.rename(
        columns={
            "ë‚ ì§œ": "Date",
            "ì¢…ê°€": "Close",
            "ì „ì¼ë¹„": "Change",
            "ì‹œê°€": "Open",
            "ê³ ê°€": "High",
            "ì €ê°€": "Low",
            "ê±°ë˜ëŸ‰": "Volume",
        }
    )

    for col in ["Close", "Open", "High", "Low", "Volume"]:
        s = (
            df[col].astype(str)
            .str.replace(",", "", regex=False)
            .str.replace("-", "0", regex=False)
            .str.strip()
        )
        df[col] = pd.to_numeric(s, errors="coerce").fillna(0).astype("int64")

    df["Date"] = pd.to_datetime(df["Date"], format="%Y.%m.%d", errors="coerce")
    df = df.dropna(subset=["Date"])
    return df[["Date", "Close", "Open", "High", "Low", "Volume"]]


def daily_prices_naver(code: str, pages: int = 30, workers: int = 8) -> pd.DataFrame:
    pages = max(1, int(pages))
    workers = max(1, int(workers))

    with ThreadPoolExecutor(max_workers=workers) as ex:
        futures = [ex.submit(_fetch_page, code, p) for p in range(1, pages + 1)]
        results = []
        for f in as_completed(futures):
            try:
                results.append(f.result())
            except Exception:
                pass

    frames = [df for df in results if df is not None and not df.empty]
    if not frames:
        return pd.DataFrame(columns=["Date", "Close", "Open", "High", "Low", "Volume"])

    out = pd.concat(frames, ignore_index=True)
    out = out.drop_duplicates(subset=["Date"]).sort_values("Date").reset_index(drop=True)
    return out


# =============================
# Indicators / Signals / Analysis
# =============================
def add_moving_averages(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    for w in FIXED_WINDOWS:
        out[f"MA{w}"] = out["Close"].rolling(window=w, min_periods=w).mean()
    return out


def add_derivative_features(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["d1_Close"] = out["Close"].diff()
    out["d2_Close"] = out["d1_Close"].diff()

    for w in FIXED_WINDOWS:
        col = f"MA{w}"
        if col in out.columns:
            out[f"d1_{col}"] = out[col].diff()
            out[f"d2_{col}"] = out[f"d1_{col}"].diff()
    return out


def alarm_operator(df: pd.DataFrame) -> str:
    cs, cl = "MA5", "MA120"
    if cs not in df.columns or cl not in df.columns:
        return "âš–ï¸ í•„ìš”í•œ ì´ë™í‰ê·  ì»¬ëŸ¼(MA5/MA120)ì´ ì—†ìŠµë‹ˆë‹¤."

    tmp = df.dropna(subset=[cs, cl])
    if len(tmp) < 2:
        return "âš–ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    last = tmp.iloc[-1]
    prev = tmp.iloc[-2]

    if (last[cs] > last[cl]) and (prev[cs] <= prev[cl]):
        return "ğŸ“ˆ ê³¨ë“ í¬ë¡œìŠ¤(5â†—120)."
    elif (last[cs] < last[cl]) and (prev[cs] >= prev[cl]):
        return "ğŸ“‰ ë°ë“œí¬ë¡œìŠ¤(5â†˜120)."
    return "âš–ï¸ íŠ¹ë³„í•œ ì‹ í˜¸ ì—†ìŒ"


def detect_local_extrema(df: pd.DataFrame, window: int = 1) -> pd.DataFrame:
    work = df.copy().reset_index(drop=True)
    n = len(work)
    is_peak = [False] * n
    is_trough = [False] * n

    window = max(1, int(window))
    for i in range(window, n - window):
        center = work.at[i, "Close"]
        left = work.at[i - window, "Close"]
        right = work.at[i + window, "Close"]

        if center > left and center >= right:
            is_peak[i] = True
        if center < left and center <= right:
            is_trough[i] = True

    work["is_peak"] = is_peak
    work["is_trough"] = is_trough
    return work


def add_trend_labels(df: pd.DataFrame) -> pd.DataFrame:
    work = add_moving_averages(df.copy())
    work = add_derivative_features(work)

    labels = []
    for _, row in work.iterrows():
        d1_ma60 = row.get("d1_MA60", 0)
        d1_ma120 = row.get("d1_MA120", 0)
        ma60 = row.get("MA60", np.nan)
        ma120 = row.get("MA120", np.nan)

        label = "transition"
        if pd.notna(ma60) and pd.notna(ma120):
            if (d1_ma60 > 0) and (d1_ma120 > 0) and (ma60 > ma120):
                label = "bull"
            elif (d1_ma60 < 0) and (d1_ma120 < 0) and (ma60 < ma120):
                label = "bear"
        labels.append(label)

    work["trend_label"] = labels
    return work


def math_analysis_report(df: pd.DataFrame, horizon: int = 5) -> str:
    if df.empty or len(df) < 150:
        return "ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìˆ˜í•™ì  ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ 150ê°œ ì´ìƒ í•„ìš”)"

    horizon = max(1, int(horizon))

    work = add_derivative_features(df.copy())
    future_col = f"future_ret_{horizon}"
    work[future_col] = work["Close"].shift(-horizon) / work["Close"] - 1.0

    cond_regime = (
        (work.get("d1_MA60", 0) > 0)
        & (work.get("d1_MA20", 0) > 0)
        & (work.get("MA20", 0) > work.get("MA60", 0))
    )

    cond_pullback = (
        (work.get("d1_MA5", 0) < 0)
        & (work["Close"] < work.get("MA5", work["Close"] * 0 + float("inf")))
        & (work["Close"] < work.get("MA20", work["Close"] * 0 + float("inf")))
    )

    pattern = cond_regime & cond_pullback
    pattern_df = work.loc[pattern].dropna(subset=[future_col])

    total = len(pattern_df)
    current = work.iloc[-1]
    now_regime = bool(cond_regime.iloc[-1])
    now_pullback = bool(cond_pullback.iloc[-1])

    lines: List[str] = []
    lines.append(f"[ìˆ˜í•™ì  ë¶„ì„ ìš”ì•½ - í–¥í›„ {horizon}ê±°ë˜ì¼ ê¸°ì¤€]")
    lines.append("1) í˜„ì¬ ì´ë™í‰ê· ì„  ê¸°ìš¸ê¸° ìƒíƒœ:")

    for w in FIXED_WINDOWS:
        v_col = f"d1_MA{w}"
        if v_col in work.columns and pd.notna(current.get(v_col)):
            val = float(current[v_col])
            if val > 0:
                direction = "ìƒìŠ¹(ìš°ìƒí–¥)"
            elif val < 0:
                direction = "í•˜ë½(ìš°í•˜í–¥)"
            else:
                direction = "ê±°ì˜ ë³´í•©"
            lines.append(f"   - {w:3}ì¼ì„ : {direction} (ìµœê·¼ ê¸°ìš¸ê¸°: {val:.2f})")

    lines.append("\n2) í˜„ì¬ íŒ¨í„´ íŒë‹¨:")
    if now_regime and now_pullback:
        lines.append("   - ìƒíƒœ: 'ìƒìŠ¹ ì¶”ì„¸ ì† ë‹¨ê¸° ì¡°ì •' íŒ¨í„´ì— í•´ë‹¹í•©ë‹ˆë‹¤.")
    elif now_regime and not now_pullback:
        lines.append("   - ìƒíƒœ: ìƒìŠ¹ ì¶”ì„¸ëŠ” ìœ ì§€ ì¤‘ì´ì§€ë§Œ, ë‹¨ê¸° ì¡°ì • êµ¬ê°„ì€ ì•„ë‹™ë‹ˆë‹¤.")
    elif (not now_regime) and now_pullback:
        lines.append("   - ìƒíƒœ: ë‹¨ê¸° ì¡°ì •ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, ì¥ê¸° ì¶”ì„¸(20/60 ê¸°ì¤€)ê°€ ëª…í™•í•œ ìƒìŠ¹ì€ ì•„ë‹™ë‹ˆë‹¤.")
    else:
        lines.append("   - ìƒíƒœ: ìƒìŠ¹ ì¶”ì„¸ë„, ì „í˜•ì ì¸ ë‹¨ê¸° ì¡°ì • íŒ¨í„´ë„ ì•„ë‹™ë‹ˆë‹¤.")

    lines.append("\n3) ê³¼ê±° ë°ì´í„°ì—ì„œ ê°™ì€ íŒ¨í„´ì˜ ì„±ê³¼:")
    if total < 5:
        lines.append(f"   - ë™ì¼ íŒ¨í„´ ë°œìƒ íšŸìˆ˜: {total}íšŒ (5íšŒ ë¯¸ë§Œ â†’ í†µê³„ì  ì‹ ë¢°ë„ ë‚®ìŒ)")
        return "\n".join(lines)

    avg_ret = float(pattern_df[future_col].mean())
    win_rate = float((pattern_df[future_col] > 0).mean())
    max_ret = float(pattern_df[future_col].max())
    min_ret = float(pattern_df[future_col].min())

    lines.append(f"   - ë™ì¼ íŒ¨í„´ ë°œìƒ íšŸìˆ˜: {total}íšŒ")
    lines.append(f"   - í‰ê·  {horizon}ì¼ ìˆ˜ìµë¥ : {avg_ret * 100:.2f}%")
    lines.append(f"   - ìƒìŠ¹í•œ ë¹„ìœ¨(ìŠ¹ë¥ ): {win_rate * 100:.1f}%")
    lines.append(f"   - ìµœê³  {horizon}ì¼ ìˆ˜ìµë¥ : {max_ret * 100:.2f}%")
    lines.append(f"   - ìµœì € {horizon}ì¼ ìˆ˜ìµë¥ : {min_ret * 100:.2f}%")
    lines.append("\nâ€» ìœ„ í†µê³„ëŠ” ê³¼ê±° íŒ¨í„´ ë¶„ì„ ê²°ê³¼ì¼ ë¿, ë¯¸ë˜ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return "\n".join(lines)


# =============================
# Backtest (MA20/60)
# =============================
def _max_drawdown(equity: pd.Series) -> float:
    cum_max = equity.cummax()
    dd = (equity - cum_max) / cum_max
    return float(dd.min())


def backtest_ma20_60_strategy(
    df: pd.DataFrame,
    fee_rate: float = 0.0005,
    initial_cash: float = 10_000_000.0
) -> dict:
    work = df.copy()
    if "MA20" not in work.columns or "MA60" not in work.columns:
        work = add_moving_averages(work)
    work = add_derivative_features(work)

    for col in ["Close", "MA20", "MA60", "d1_MA20"]:
        if col not in work.columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {col}")

    work = work.dropna(subset=["Close", "MA20", "MA60", "d1_MA20"]).reset_index(drop=True)

    cash = float(initial_cash)
    shares = 0.0
    equity_list: List[float] = []
    position_flag: List[int] = []
    trades: List[dict] = []

    in_position = False
    entry_price = None
    entry_idx = None

    for i, row in work.iterrows():
        price = float(row["Close"])
        ma20 = float(row["MA20"])
        ma60 = float(row["MA60"])
        d1_ma20 = float(row["d1_MA20"])

        if in_position:
            if (price < ma20) or (ma20 < ma60):
                sell_price = price * (1 - fee_rate)
                cash = shares * sell_price
                trades.append({
                    "entry_idx": entry_idx,
                    "exit_idx": i,
                    "entry_price": entry_price,
                    "exit_price": sell_price,
                    "ret": sell_price / entry_price - 1.0,
                })
                shares = 0.0
                in_position = False
                entry_price = None
                entry_idx = None
        else:
            if (price > ma20) and (ma20 > ma60) and (d1_ma20 > 0):
                buy_price = price * (1 + fee_rate)
                shares = cash / buy_price
                cash = 0.0
                in_position = True
                entry_price = buy_price
                entry_idx = i

        equity = cash + shares * price
        equity_list.append(equity)
        position_flag.append(1 if in_position else 0)

    work["equity"] = equity_list
    work["position"] = position_flag
    work["equity_ret"] = work["equity"].pct_change().fillna(0.0)

    total_return = work["equity"].iloc[-1] / initial_cash - 1.0
    mdd = _max_drawdown(work["equity"])

    mean_ret = work["equity_ret"].mean()
    std_ret = work["equity_ret"].std()
    sharpe = float((mean_ret / std_ret) * np.sqrt(252)) if std_ret > 0 else 0.0

    n_trades = len(trades)
    if n_trades > 0:
        rets = np.array([t["ret"] for t in trades], dtype=float)
        win_rate = float((rets > 0).mean())
        avg_trade_ret = float(rets.mean())
    else:
        win_rate = 0.0
        avg_trade_ret = 0.0

    equity_curve = work[["Date", "equity", "position"]].copy()
    equity_curve["Date"] = equity_curve["Date"].dt.strftime("%Y-%m-%d")

    return {
        "total_return": float(total_return),
        "MDD": float(mdd),
        "sharpe": float(sharpe),
        "n_trades": int(n_trades),
        "win_rate": float(win_rate),
        "avg_trade_ret": float(avg_trade_ret),
        "trades": trades,
        "equity_curve": {
            "date": equity_curve["Date"].tolist(),
            "equity": equity_curve["equity"].astype(float).tolist(),
            "position": equity_curve["position"].astype(int).tolist(),
        },
    }


# =============================
# High-level analyze (for iOS)
# =============================
def stock_calculator(code: str, pages: int = 30, workers: int = 8) -> pd.DataFrame:
    prices = daily_prices_naver(code=code, pages=pages, workers=workers)
    prices = add_moving_averages(prices)
    return prices


def _cache_key(code: str, pages: int, horizon: int) -> str:
    return f"{code}|p={pages}|h={horizon}"


def analyze(code_or_name: str, pages: int = 30, workers: int = 8, horizon: int = 5,
            tail_n: int = 260, extrema_window: int = 2) -> dict:
    code = resolve_to_code(code_or_name)
    if not code:
        return {"ok": False, "error": "cannot_resolve_code", "input": code_or_name}

    pages = max(1, int(pages))
    horizon = max(1, int(horizon))
    tail_n = max(50, int(tail_n))

    key = _cache_key(code, pages, horizon)
    now = time.time()
    if key in _CACHE and (now - _CACHE[key]["ts"] < CACHE_TTL_SEC):
        return _CACHE[key]["data"]

    df = stock_calculator(code, pages=pages, workers=workers)
    if df.empty or len(df) < 10:
        return {"ok": False, "error": "no_data", "code": code}

    signal = alarm_operator(df)
    trend_df = add_trend_labels(df)
    trend_label = str(trend_df["trend_label"].iloc[-1])

    report = math_analysis_report(df, horizon=horizon)

    ext_df = detect_local_extrema(df, window=extrema_window)
    recent_ext = ext_df.tail(60)
    peaks = recent_ext[recent_ext["is_peak"]].tail(10)
    troughs = recent_ext[recent_ext["is_trough"]].tail(10)

    tail = df.tail(tail_n).copy()
    tail["Date"] = tail["Date"].dt.strftime("%Y-%m-%d")

    data = {
        "ok": True,
        "code": code,
        "signal": signal,
        "trend_label": trend_label,
        "report": report,
        "meta": {
            "pages": pages,
            "horizon": horizon,
            "tail_n": tail_n,
            "windows": list(FIXED_WINDOWS),
            "last_date": str(tail["Date"].iloc[-1]),
            "last_close": int(tail["Close"].iloc[-1]),
        },
        "series": {
            "date": tail["Date"].tolist(),
            "close": tail["Close"].astype(int).tolist(),
            "ma5": tail["MA5"].round(3).where(~tail["MA5"].isna(), None).tolist(),
            "ma20": tail["MA20"].round(3).where(~tail["MA20"].isna(), None).tolist(),
            "ma60": tail["MA60"].round(3).where(~tail["MA60"].isna(), None).tolist(),
            "ma120": tail["MA120"].round(3).where(~tail["MA120"].isna(), None).tolist(),
        },
        "extrema_recent": {
            "peaks": [
                {"date": str(row["Date"].date()), "close": int(row["Close"])}
                for _, row in peaks.iterrows()
            ],
            "troughs": [
                {"date": str(row["Date"].date()), "close": int(row["Close"])}
                for _, row in troughs.iterrows()
            ],
        },
    }

    _CACHE[key] = {"ts": now, "data": data}
    return data


# =============================
# FastAPI App
# =============================
app = FastAPI(title="Stock Analysis API (Naver)", version="1.0")

# iOS ì•±ì—ì„œ í˜¸ì¶œ í¸í•˜ê²Œ CORS í—ˆìš© (ë°°í¬ ì‹œì—ëŠ” origin ì œí•œ ê¶Œì¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
def health():
    return {"ok": True, "ts": int(time.time())}


@app.get("/analyze")
def api_analyze(
    q: str = Query(..., description="ì¢…ëª©ì½”ë“œ(6ìë¦¬) ë˜ëŠ” ì¢…ëª©ëª… (ì˜ˆ: 005930 / ì‚¼ì„±ì „ì)"),
    pages: int = Query(30, ge=1, le=200),
    workers: int = Query(8, ge=1, le=32),
    horizon: int = Query(5, ge=1, le=60),
    tail_n: int = Query(260, ge=50, le=2000),
):
    data = analyze(q, pages=pages, workers=workers, horizon=horizon, tail_n=tail_n)
    if not data.get("ok", False):
        raise HTTPException(status_code=400, detail=data)
    return data


@app.get("/backtest")
def api_backtest(
    q: str = Query(..., description="ì¢…ëª©ì½”ë“œ(6ìë¦¬) ë˜ëŠ” ì¢…ëª©ëª…"),
    pages: int = Query(80, ge=1, le=300),
    workers: int = Query(8, ge=1, le=32),
    fee_rate: float = Query(0.0005, ge=0.0, le=0.01),
    initial_cash: float = Query(10_000_000.0, ge=1_000.0, le=1_000_000_000.0),
):
    code = resolve_to_code(q)
    if not code:
        raise HTTPException(status_code=400, detail={"ok": False, "error": "cannot_resolve_code", "input": q})

    df = stock_calculator(code, pages=pages, workers=workers)
    if df.empty or len(df) < 100:
        raise HTTPException(status_code=400, detail={"ok": False, "error": "no_data_or_too_short", "code": code})

    try:
        result = backtest_ma20_60_strategy(df, fee_rate=fee_rate, initial_cash=initial_cash)
    except Exception as e:
        raise HTTPException(status_code=500, detail={"ok": False, "error": "backtest_failed", "message": str(e)})

    return {"ok": True, "code": code, "result": result}


# =============================
# Run (local)
# =============================
# í„°ë¯¸ë„:
#   pip install fastapi uvicorn requests pandas numpy beautifulsoup4 lxml
#   uvicorn server_stock_api:app --host 0.0.0.0 --port 8000
#
# í…ŒìŠ¤íŠ¸:
#   http://localhost:8000/health
#   http://localhost:8000/analyze?q=ì‚¼ì„±ì „ì
#   http://localhost:8000/analyze?q=005930&pages=60
#   http://localhost:8000/backtest?q=005930